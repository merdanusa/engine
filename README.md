# ğŸŒ AI Router Engine

An intelligent **multi-model AI router** that dynamically selects the best model (Gemini or OpenRouter) based on the prompt type â€” **Turkmen language**, **coding**, **science**, or **general** queries.

It automatically detects the content type and routes requests to the most suitable LLM, with built-in **retry logic**, **fallback handling**, and **dual responses** for scientific topics.

---

## ğŸš€ Features

âœ… **Automatic model routing** based on content type
âœ… **Supports multiple APIs:** Gemini & OpenRouter
âœ… **Turkmen language detection**
âœ… **Coding & science keyword detection**
âœ… **Dual-response mode** for math/science queries
âœ… **Error recovery and fallback model**
âœ… Works on **client or server side** (with API key protection on backend)

---

## ğŸ§  Model Routing Logic

| Type               | Detection                                    | Model Used                                     | Notes                           |
| ------------------ | -------------------------------------------- | ---------------------------------------------- | ------------------------------- |
| **Turkmen text**   | Turkmen letters or words                     | ğŸŸ¢ `Gemini`                                    | Best for local language content |
| **Coding prompts** | Keywords like â€œappâ€, â€œfunctionâ€, â€œAPIâ€       | ğŸ’» `deepseek/deepseek-coder`                   | Optimized for code              |
| **Science/math**   | Keywords like â€œphysicsâ€, â€œequationâ€, â€œsolveâ€ | âš›ï¸ `meta-llama/llama-3.1-8b-instruct` + Gemini | Fetches **dual responses**      |
| **General**        | No match                                     | âœ¨ `Gemini`                                    | Default route                   |
| **Fallback**       | On all failure                               | ğŸ§© `mistralai/mistral-7b-instruct`             | Reliable backup model           |

---

## ğŸ“¦ Installation

```bash
# Using npm
npm install dotenv

# or yarn
yarn add dotenv
```

---

## âš™ï¸ Environment Setup

Create a `.env` file in the project root:

```bash
OPEN_ROUTER_API_KEY=your_openrouter_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
```

If you're using this on **client-side (Vite)**, ensure your keys are prefixed properly:

```bash
VITE_OPEN_ROUTER_API_KEY=your_openrouter_api_key_here
VITE_GEMINI_API_KEY=your_gemini_api_key_here
```

Then update:

```js
const OPEN_ROUTER_API_KEY = import.meta.env.VITE_OPEN_ROUTER_API_KEY;
const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY;
```

---

## ğŸ§© Usage Example

```js
import engine from "./engine.js";

(async () => {
  const result1 = await engine("Salam, nÃ¤hili?"); // Turkmen â†’ Gemini
  console.log(result1);

  const result2 = await engine("Create a todo app in React"); // Coding â†’ DeepSeek
  console.log(result2);

  const result3 = await engine("Explain quantum physics"); // Science â†’ Dual (Gemini + LLaMA)
  console.log(result3);
})();
```

---

## ğŸ” Example Output

```js
{
  model: "openrouter-coding",
  response: "// Here's how to build a simple React todo app..."
}
```

For science/math queries:

```js
{
  model: "dual",
  responses: {
    openrouter: "Quantum physics is the study of matter at atomic scales...",
    gemini: "In quantum physics, particles behave both as waves and particles..."
  }
}
```

---

## ğŸ§± Project Structure

```
.
â”œâ”€â”€ engine.js          # Core logic
â”œâ”€â”€ package.json
â”œâ”€â”€ .env               # API keys
â””â”€â”€ README.md
```

---

## ğŸª„ API Models Used

| Provider       | Model                                   | Purpose                      |
| -------------- | --------------------------------------- | ---------------------------- |
| **Google**     | `gemini-pro`                            | General / Turkmen / fallback |
| **OpenRouter** | `deepseek/deepseek-coder`               | Coding                       |
| **OpenRouter** | `meta-llama/llama-3.1-8b-instruct:free` | Science                      |
| **OpenRouter** | `mistralai/mistral-7b-instruct:free`    | Fallback                     |

---

## âš ï¸ Notes

- Avoid exposing your **API keys** in client-side code.
- To safely use on frontend, create a small backend proxy (Node.js or Cloudflare Worker).
- Built-in retries with exponential delay are already implemented.

---

## ğŸ§‘â€ğŸ’» Author

**Merdan** â€” Full-stack developer passionate about AI, React, and backend systems.
ğŸ’¬ Telegram: `@merdanusa`
ğŸŒ Project type: _Client/Engine module_

---

Would you like me to make it **developer-doc style (like an NPM package readme)** or **GitHub open-source style (with badges, install section, and license)**?
